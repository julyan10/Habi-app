import streamlit as st
import pandas as pd
import plotly.express as px
import folium
from streamlit_folium import st_folium
from geopy.geocoders import Nominatim
from geopy.extra.rate_limiter import RateLimiter
from folium import Circle
from folium.plugins import MarkerCluster
from math import radians, cos, sin, sqrt, atan2
import os

st.set_page_config(layout="wide")
st.title("ğŸ  Dashboard de Propiedades - Habi")

# --- Cargar datos con ciudad precargada ---
@st.cache_data
def load_data():
    csv_con_ciudad = "base_prueba_ciudades.csv"

    # Si ya existe el archivo con ciudades, lo carga directamente
    if os.path.exists(csv_con_ciudad):
        df = pd.read_csv(csv_con_ciudad)
        return df

    # Si no existe, carga el original y crea la columna 'ciudad'
    df = pd.read_csv("base prueba bi mid.csv")

    geolocator = Nominatim(user_agent="geoapiHabi")
    reverse = RateLimiter(geolocator.reverse, min_delay_seconds=1)

    def get_city(lat, lon):
        try:
            location = reverse((lat, lon), exactly_one=True, language='es')
            if location and 'address' in location.raw:
                address = location.raw['address']
                return address.get('city') or address.get('town') or address.get('village')
        except:
            return None

    # Aplicar geolocalizaciÃ³n y crear columna ciudad
    df["ciudad"] = df.apply(lambda row: get_city(row["latitud"], row["longitud"]), axis=1)

    # Guardar el nuevo CSV con ciudad incluida
    df.to_csv(csv_con_ciudad, index=False)

    return df

# Cargar los datos
df = load_data()

# --- Filtros globales ---
st.markdown("""
### ğŸ§  Contexto del reto

El rendimiento del equipo de Brokers (el equipo encargado de las ventas inmobiliarias) ha disminuido considerablemente desde hace 4 meses. Usted estÃ¡ en el equipo encargado de mejorar la productividad, Â¿cuÃ¡l serÃ­a su acciÃ³n en los dos prÃ³ximos sprints?

**SoluciÃ³n 1:**

#### Sprint 1: DiagnÃ³stico y anÃ¡lisis  
**Objetivo:** Identificar causas especÃ­ficas de la baja productividad.

1. **AnÃ¡lisis de datos histÃ³ricos de desempeÃ±o (Ãºltimos 6-12 meses):**
   - Ventas por broker, zona y tipo de propiedad.
   - Tiempo promedio de cierre por propiedad.
   - NÃºmero de contactos y conversiones.

2. **Entrevistas y focus group con brokers:**
   - Identificar barreras operativas, tÃ©cnicas o motivacionales.
   - Recoger insumos cualitativos sobre el proceso de ventas.

3. **RevisiÃ³n de KPIs actuales:**
   - Verificar si estÃ¡n alineados con los objetivos del negocio.
   - Evaluar si los incentivos estÃ¡n bien estructurados.

4. **Mapeo del funnel de ventas:**
   - Identificar puntos crÃ­ticos donde se pierden oportunidades (p. ej., baja conversiÃ³n en visitas o negociaciÃ³n).

#### Sprint 2: ImplementaciÃ³n de quick wins  
**Objetivo:** Implementar acciones para mejorar productividad mientras se diseÃ±a una estrategia a mediano plazo.

1. **AutomatizaciÃ³n de tareas repetitivas:**
   - Herramientas para agendar visitas o responder preguntas frecuentes.

2. **CapacitaciÃ³n express:**
   - Taller de habilidades blandas (negociaciÃ³n, objeciones).
   - Uso efectivo de herramientas tecnolÃ³gicas (CRM, dashboards).

3. **Dashboard de desempeÃ±o en tiempo real:**
   - VisualizaciÃ³n por broker para promover la autogestiÃ³n del rendimiento.
   - Ranking interno con KPIs claros (visitas, cierres, seguimiento).

4. **RevisiÃ³n de zonas asignadas:**
   - Redistribuir zonas si hay desequilibrio entre demanda y cobertura.

---

### âš½ Habi Soccer â€“ Nuevo producto

Habi va a lanzar un nuevo producto **Â«Habi fÃºtbolÂ»**, en el que la empresa comprarÃ¡ campos sintÃ©ticos y los venderÃ¡ con cÃ©sped nuevo y buenas gradas. Al tratarse de un nuevo negocio, no disponemos de una estructura de base de datos para medirlo.

#### Â¿QuÃ© pasos darÃ­as para construir un MVP que permita a los directivos seguir el rendimiento de Habi Soccer?

---

#### Fase 1: DiseÃ±o de estructura y captura de datos

1. **Definir los indicadores clave (KPIs):**
   - NÂº de campos adquiridos / vendidos.
   - Tiempo promedio de adecuaciÃ³n.
   - Costo total vs precio de venta por campo.
   - Rentabilidad por campo.
   - UbicaciÃ³n y demanda por zona.
   - % de avance de cada proyecto (compra, adecuaciÃ³n, venta).

2. **DiseÃ±ar el modelo de datos inicial (Tablas principales):**
   - **Campos:** ID, direcciÃ³n, tamaÃ±o, zona, estado actual.
   - **Adecuaciones:** fecha inicio/fin, tipo de mejora, proveedor, costo.
   - **Ventas:** comprador, precio, fecha cierre.
   - **Estados del proceso:** pendiente, en adecuaciÃ³n, en venta, vendido.

3. **Definir herramientas de captura:**
   - Formulario interno con Google Forms, Power Apps o Airtable.
   - Almacenamiento temporal en Google Sheets o base SQL ligera.

---

#### Fase 2: VisualizaciÃ³n y anÃ¡lisis

1. **Conectar los datos a Power BI / Looker Studio:**
   - Dashboard con filtros por zona, estado y fechas.
   - KPIs en tarjetas: campos activos, vendidos, ingresos totales.
   - Mapa con localizaciÃ³n de campos.
   - GrÃ¡ficos de evoluciÃ³n temporal de ventas y adecuaciones.

2. **SegmentaciÃ³n geogrÃ¡fica:**
   - AnÃ¡lisis de demanda por zona para identificar zonas de oportunidad.

---

#### Fase 3: ValidaciÃ³n e iteraciÃ³n

1. **Probar el MVP con los usuarios clave (comercial y directivos):**
   - Obtener feedback para ajustar los datos y visualizaciones.

2. **Iterar sobre el modelo:**
   - AÃ±adir nuevos campos, mÃ©tricas o integraciones con sistemas existentes (ERP, CRM).
---

### ğŸ§  Pregunta 3:

> Escriba una sentencia SELECT para recuperar la ciudad, el precio de venta y la fecha de creaciÃ³n de todos los inmuebles que se han publicado por un precio superior al precio medio de venta de todos los inmuebles publicados para Carolina Castro Jaramillo.

**âœ… Respuesta en SQL:**

SELECT Ciudad, Precio_venta, Fecha_creacion  
FROM propiedades  
WHERE Publicado_por = 'Carolina Castro Jaramillo'  
AND Precio_venta > (  
Â Â Â Â SELECT AVG(Precio_venta)  
Â Â Â Â FROM propiedades  
Â Â Â Â WHERE Publicado_por = 'Carolina Castro Jaramillo'  
);

---

### ğŸ§  Pregunta 4:

> Â¿CuÃ¡l es el promedio de precios de venta por tamaÃ±o de propiedad (en metros cuadrados) para propiedades que tienen al menos 3 habitaciones y 2 baÃ±os?  
> Considere solo promedio de precio de venta mayor a 80.000.000 y muestre el top 20 ordenado de forma descendente por el promedio del precio de venta.

**âœ… Respuesta en SQL:**

SELECT TamaÃ±o,  
Â Â Â Â AVG(Precio_venta) AS Promedio_Precio_Venta  
FROM propiedades  
WHERE N_habitaciones >= 3  
Â Â Â Â AND N_baÃ±os >= 2  
GROUP BY TamaÃ±o  
HAVING AVG(Precio_venta) > 80000000  
ORDER BY Promedio_Precio_Venta DESC  
LIMIT 20;
""")

# --- SecciÃ³n: AnÃ¡lisis de propiedades ---
st.header("ğŸ“Š AnÃ¡lisis de propiedades")

with st.sidebar:
    st.markdown("### ğŸ¯ Filtros de Propiedades")

    alcobas_unique = sorted(df['alcobas'].dropna().unique())
    banios_unique = sorted(df['banios'].dropna().unique())

    alcobas_filter = st.multiselect("Filtrar por Alcobas", alcobas_unique, default=alcobas_unique)
    banios_filter = st.multiselect("Filtrar por BaÃ±os", banios_unique, default=banios_unique)

    min_area = int(df['area_m2'].min())
    max_area = int(df['area_m2'].max())
    area_min, area_max = st.slider(
        "Filtrar por Ãrea (m2)",
        min_value=min_area,
        max_value=max_area,
        value=(min_area, max_area),
        step=1
    )

# --- Aplicar filtros ---
df_filtrado = df[
    df['alcobas'].isin(alcobas_filter) &
    df['banios'].isin(banios_filter) &
    (df['area_m2'] >= area_min) & (df['area_m2'] <= area_max)
]

# --- Mostrar tabla filtrada ---
st.subheader("ğŸ“‹ Tabla de propiedades filtradas")
st.dataframe(
    df_filtrado[["nombre_cliente", "precio", "area_m2", "banios", "alcobas", "ciudad"]].rename(columns={
        "nombre_cliente": "Cliente",
        "precio": "Precio",
        "banios": "N_BaÃ±os",
        "alcobas": "N_Alcobas",
        "area_m2": "Ãrea (m2)",
        "ciudad": "Ciudad"
    })
)

# --- GrÃ¡fico de barras: nÃºmero de propiedades por ciudad ---
st.subheader("ğŸ™ï¸ DistribuciÃ³n de propiedades por ciudad")

ciudades_count = df_filtrado["ciudad"].value_counts().reset_index()
ciudades_count.columns = ["Ciudad", "Cantidad de propiedades"]

fig_ciudades = px.bar(
    ciudades_count,
    x="Ciudad",
    y="Cantidad de propiedades",
    title="Cantidad de propiedades por ciudad",
    text_auto=True
)
st.plotly_chart(fig_ciudades)

# --- Mapa de propiedades por coordenadas ---
st.subheader("ğŸ—ºï¸ Mapa de propiedades por zona")
fig_map = px.scatter_mapbox(df_filtrado,
                            lat="latitud",
                            lon="longitud",
                            size="precio",
                            color_discrete_sequence=["red"],
                            zoom=10,
                            height=500,
                            hover_name="nombre_cliente",
                            mapbox_style="carto-positron")
st.plotly_chart(fig_map)

# --- Mapa por coordenadas ingresadas ---
st.header("ğŸ” Propiedades en un radio de 500 metros")
st.markdown(
    "ğŸ” *Ingresa una latitud y longitud para identificar propiedades publicadas dentro de un radio de 500 metros.*"
)
col1, col2 = st.columns(2)
with col1:
    lat_input = st.number_input("Latitud", value=4.5997, format="%.6f")
with col2:
    lon_input = st.number_input("Longitud", value=-74.0817, format="%.6f")

# FunciÃ³n para calcular distancia
def haversine(lat1, lon1, lat2, lon2):
    R = 6371.0
    dlat = radians(lat2 - lat1)
    dlon = radians(lon2 - lon1)
    a = sin(dlat / 2)**2 + cos(radians(lat1)) * cos(radians(lat2)) * sin(dlon / 2)**2
    c = 2 * atan2(sqrt(a), sqrt(1 - a))
    return R * c * 1000

# Calcular distancia y filtrar cercanas
df["distancia_m"] = df.apply(lambda row: haversine(lat_input, lon_input, row["latitud"], row["longitud"]), axis=1)
df_cercanas = df[df["distancia_m"] <= 500]

# Mapa y tabla en columnas
col_mapa, col_tabla = st.columns([2, 1])

with col_mapa:
    m = folium.Map(location=[lat_input, lon_input], zoom_start=16)
    Circle(location=(lat_input, lon_input), radius=500, color='blue', fill=True, fill_opacity=0.1).add_to(m)
    marker_cluster = MarkerCluster().add_to(m)

    for _, row in df_cercanas.iterrows():
        folium.Marker(location=[row["latitud"], row["longitud"]],
                      popup=f"{row['nombre_cliente']} - ${row['precio']}").add_to(marker_cluster)

    st_data = st_folium(m, width=700, height=450)

with col_tabla:
    st.write(f"**Propiedades encontradas:** {len(df_cercanas)}")
    df_cercanas["ciudad"] = df_cercanas.apply(lambda row: get_city(row["latitud"], row["longitud"]), axis=1)
    st.dataframe(
    df_cercanas[["nombre_cliente", "precio", "area_m2", "banios", "alcobas", "ciudad"]].rename(columns={
        "nombre_cliente": "Cliente",
        "precio": "Precio",
        "banios": "N_BaÃ±os",
        "alcobas": "N_Alcobas",
        "area_m2": "Ãrea (m2)",
        "ciudad": "Ciudad"
    })
)


